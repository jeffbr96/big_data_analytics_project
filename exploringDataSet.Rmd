---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
  word_document: default
---
### Dataset

This dataset contains 69,533 observations of 77 variables of 35 are integers over 25 are characters and almost 15 are numeric. It is a very large dataset so; I did not think that extracting just the information that I need ahead of time would not be a good idea. for now, I have decided to look at all data and pick through as well as clean the data separately. for that I think that using some generalization and getting a snapshot of what I have will yield me good insight on which questions to ask.  

```{r}
library(dplyr)
df <- read.csv("C:/Users/jeffb/OneDrive/Desktop/WSU-Spring-2022/Big Data Analitics/data-capstone-final-project/nysus.csv")

head(df)
```


This bar plot shows the types of data I have. this data probably contains a lot of good data to group by. another important aspect of this dataset is that it can generate good geographical analysis, timeseries as well as other classifications and regressions.  

```{r}
data_types <- function(frame) {
  res <- lapply(frame, class)
  res_frame <- data.frame(unlist(res))
  barplot(table(res_frame), main="Data Types", col="steelblue", ylab="Number of Features")
}

data_types(df)
```


```{r}
names(df)
library("reshape2") 
library(ggplot2)
data_long <- melt(df)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = value)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))
col <- c('Assess.Land', 'Exempt.Land', 'Exempt.Tot', 'BBL')
df1 <- df[!(names(df)) %in% col]

#removing columns with large numbers 
data_long <- melt(df1)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = value)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))

col <- c('Total.Area')
df1 <- df1[!(names(df1)) %in% col]

#removing columns with large numbers 
data_long <- melt(df1)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = value)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))

col <- c('Total.Gross.Area.Structures', 'Commercial.Floor.Area', 'Other.Floor.Area', 'BIN')
df1 <- df1[!(names(df1)) %in% col]

#removing columns with large numbers 
data_long <- melt(df1)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = value)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))

```
to put this dataset to the test i ran boxplot of all varibles and was able to verify that 4 values stood out with outstanding values. I decided then to investigate them individually.
```{r}
col = c("Assess.Land", "Exempt.Land", "Exempt.Tot", "BBL")
df1 <- df[,col]
df1
data_long <- melt(df1)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = value, fill = variable)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))
```
the values for Assess.Land, Exempt.Land and Exempt.Land are squashed at the bottom. this makes for a data set hard to visualize.
```{r}
ggplot(data_long, aes(x = variable, y = log(value), fill = variable)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))
```
using a log tranformation on the y value helps bring the first three varibles to a better perspective but BBL does not fare as nicely. so it is best to look at all the variables separetly.  

```{r}
col = c("Assess.Land", "Exempt.Land", "Exempt.Tot")
df1 <- df[,col]
df1
data_long <- melt(df1)                                      # Reshaping data frame
head(data_long)       
ggplot(data_long, aes(x = variable, y = log(value), fill = variable)) +            # Applying ggplot function
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(angle = 90))
```
I can now see that they have some resemblance and share some regularity but I need to truly see what this values mean.

```{r}
boxplot(df$Total.Area)
boxplot(log(df$Total.Area))

```


```{r}
library(dplyr)
library(ggplot2)
library(viridis)
par(mfrow = c(1, 3)) 
plot(df$Assess.Land)
plot(df$Exempt.Land)
plot(df$Exempt.Tot)

ggplot(df, aes(Borough, Assess.Land, size = Assess.Land, col = "red")) +
  geom_point()
summary(df$Assess.Land)

df$newfl <- cut(df$Num.Floors,
              breaks=c(0, 2, 5, 50, 500),
              labels=c('house', 'building', 'tall building', 'sky scraper')) 
na.exclude(df$newfl) 

df %>%
  group_by(Borough) %>%
    group_by(Num.Floors) %>%
        ggplot(aes(Longitude, Latitude, size = Assess.Land)) +
          geom_point(shape = 21, aes(alpha = 0.25, color = factor(Borough), fill = newfl)) +
          scale_color_brewer(palette = "Dark2") +
          scale_colour_discrete(na.translate = F)
      

summary(df$Num.Floors)
names(df)
df$Num.Floors

df$newfl

filter(df, !is.na(newfl)) %>% 
  ggplot() +
  geom_bar(mapping = aes(x = Borough, fill = newfl), position = "fill")
```
I discovered that Asses.Land is the actual assessed land value for Fiscal Year 2013. it makes sense that this value can get so high in NY. The exempt land is the tax value for 2013 and exempt total is the total exempt value for the year
```{r}
library(ggplot2)
library(plyr)
library(dplyr)
plot(df$Number.Structures)
ggplot(df, aes(Land.Use.Category)) +
  geom_bar()
zerosPercentage <- colSums(df==0)/nrow(df)*100  
barplot(zerosPercentage, main = "Percentage of zero values", col = zerosPercentage, names.arg = round(zerosPercentage, 0)) 
greaterThan50 <-  which((colSums(df==0)/nrow(df)*100) > 50)
barplot(greaterThan50, main = "Percentage of zero values", col = greaterThan50, names.arg = round(greaterThan50, 0)) 
unwantedColumns <- names(which((colSums(df==0)/nrow(df)*100) > 50))
cleanedDf = df[!(names(df)) %in% unwantedColumns]
zerosPercentage <- colSums(cleanedDf==0)/nrow(cleanedDf)*100  
barplot(zerosPercentage, main = "Percentage of zero values", col = zerosPercentage, names.arg = round(zerosPercentage, 0)) 
names(which((colSums(cleanedDf==0)/nrow(cleanedDf)*100) > 0))
col <- c("Total.Area",      "Community.Board", "Lot.Front",       "Lot.Depth")
cleanedDf = cleanedDf[!(names(cleanedDf)) %in% c("Allowable.Building.to.Floor.Area")]
barplot(zerosPercentage[col], main = "Percentage of zero values", col = zerosPercentage[col], names.arg = zerosPercentage[col]) 
plot(cleanedDf[col])
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

```{r}
library(dplyr)
library(ggplot2)
library(viridis)

names(df)
df %>%
  group_by(Borough) %>%
  ggplot(aes(Borough)) +
  geom_bar()

clr = c('yellow', 'red', 'blue', 'brown', 'green')

df %>%
  group_by(Borough) %>%
  ggplot(aes(Longitude, Latitude, col = Borough, )) +
  geom_point() +
  scale_color_viridis(option = "D")
  
colors()
df %>%
  group_by(Borough) %>%
  filter(Borough == 1) %>%
  group_by(Current.Uses) %>%
  ggplot(aes(Current.Uses)) + 
  geom_boxplot() 
 
 unique(df$Current.Uses)
 df <- df[which(df$Current.Uses == "PUBLIC SCHOOL"),]
 
 ggplot(df, aes(Latitude, Longitude)) +
   geom_point()
 names(df)
 df
 

```
```{r}
df <- read.csv("C:/Users/jeffb/OneDrive/Desktop/WSU-Spring-2022/Big Data Analitics/data-capstone-final-project/nysus.csv")
library(ggmap)
library(sp)
library(tigris)
#install.packages("devtools")
#install.packages("rworldmap")
# load library
library(rworldmap)
# get map
worldmap <- getMap(resolution = "coarse")
# plot world map

# plot data on world map
plot(worldmap, xlim = c(-74, -73), ylim = c(40, 41), 
     asp = 1, bg = "lightblue", col = "black", fill = T) +
points(df$Longitude, df$Latitude, 
       col = "red", cex = .01)

library(usmap)
library(ggplot2)

map <- plot_usmap(include = c("NY"))


data <- data.frame(df$Longitude, df$Latitude)
data <- data[which(!is.na(data)),]
data <- na.exclude(data)
sum(is.na(data))
new <- data[which(!is.na(data)),]
df <- na.exclude(df)
#data$Longitude <- as.data.frame(df$Longitude)
#data$Latitude <- as.data.frame(df$Latitude)
transformed_data <- usmap_transform(data)
data
plot_usmap(include = c("NY")) +
  geom_point(data = transformed_data, aes(transformed_data$df.Longitude, transformed_data$df.Latitude),
             color = "red")

plot(map, 
     asp = 1, bg = "lightblue", col = "black", fill = T) +
points(df$Longitude, df$Latitude, 
       col = "red", cex = .01)
plot(map, 
     asp = 1, bg = "lightblue", col = "black", fill = T) +
points(data$lat, data$lon, 
       col = "red", cex = .01)
plot(df$Latitude, df$Longitude)


#plot_usmap("states") + 
#  geom_point(data = transformed_data, 
#             aes(x = x, y = y), 
#             color = "red",
#             size = 3)

#plot(map, xlim = c(-74, -73), ylim = c(40, 41), 
#     asp = 1, bg = "lightblue", col = "black", fill = T) +
#points(df$Longitude, df$Latitude, 
#       col = "red", cex = .01)

#df$Latitude

#devtools::install_github("dkahle/ggmap", ref = "tidyup")
#chicago <- get_stamenmap(bbox = c(left = -88.0225, bottom = 41.5949, 
#                                  right = -87.2713, top = 42.0677), 
#                         zoom = 11)

#ggmap(chicago)
```
```{r}
library(maps)
library(ggplot2)

maps::map('county', region = 'new york', city = "new york", col = "#5E610B") 
#map.cities(us.cities, country="NY", col = "#642EFE", cex = 0.6) # map cities recorded in us.cities to NY State
map.axes(cex.axis=0.8) 
ylim(40, 41)
title(main = "New York State by Counties", xlab = "Longitude", ylab = "Latitude",
      cex.lab = 0.1) 
points(-76, 43, 
       col = "red", cex = .8) 



  

#?ylim()
#?map  
#ylim(40, 41) +
 # xlim(-76, -72)
#df$Latitude
#df$Longitude
```

```{r}
df <- read.csv("C:/Users/jeffb/OneDrive/Desktop/WSU-Spring-2022/Big Data Analitics/data-capstone-final-project/nysus.csv")
str(df)

clf <- df[c("Borough", "Total.Area", "Num.Floors", "Ratio.Building.to.Floor.Area")]
clf <- na.exclude(clf)
print(is.na(clf))
nrow(clf)
nrow(df)
use <- df[]

sample_rows <- sample(nrow(clf), nrow(clf) * 0.75)
train <- clf[sample_rows, ]
test <- clf[-sample_rows, ]

normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }

clf <- as.data.frame(lapply(clf[,0:4], normalize))
sample_rows <- sample(nrow(clf), nrow(clf) * 0.75)
train <- clf[sample_rows, ]
test <- clf[-sample_rows, ]
labels <- df[sample_rows, ]
train
test
test <- test[which(is.na(test) == FALSE),]
train <- train[which(is.na(train) == FALSE),]
use <- use[which(is.na(use) == FALSE),]

plot(grouping(use$Current.Uses))

knn(train = train, test = test, cl = train)
```

```{r}
install.packages("naivebayes")
library(naivebayes)

# Build the location prediction model
df$Borough <- as.factor(df$Borough)

model <- naive_bayes(Borough ~ Open.Petroleum.Spill, data = df)

# Predict Thursday's 9am location
plot(model) #model 4 has more oil spills
model

# Predict Saturdays's 9am location
predict(locmodel, saturday9am)
```

